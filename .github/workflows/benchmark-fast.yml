name: Benchmark (Fast)

# Fast mode: Runs on PRs for quick trend validation
# Uses cheaper virtualized instances (c5.large, c6g.medium)

on:
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      duration:
        description: 'Benchmark duration (e.g., 15s, 30s)'
        required: false
        default: '15s'
      benchmark_mode:
        description: 'Benchmark servers to test'
        required: false
        default: 'all'
        type: choice
        options:
          - baseline
          - theoretical
          - all

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

env:
  TF_VAR_repository_url: ${{ github.server_url }}/${{ github.repository }}
  TF_VAR_benchmark_mode: fast

jobs:
  launch:
    name: Launch Fast Infrastructure
    runs-on: ubuntu-latest
    outputs:
      arm64_launched: ${{ steps.result.outputs.arm64_launched }}
      x86_launched: ${{ steps.result.outputs.x86_launched }}
      instance_mode: ${{ steps.result.outputs.instance_mode }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Try Spot Instances
        id: spot
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
        run: |
          echo "Attempting to launch spot instances..."
          if terraform apply -auto-approve; then
            echo "spot_success=true" >> $GITHUB_OUTPUT
            echo "Spot instances launched successfully"
          else
            echo "spot_success=false" >> $GITHUB_OUTPUT
            echo "Spot instances failed, will try on-demand"
          fi

      - name: Cleanup Failed Spot
        if: steps.spot.outputs.spot_success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
        run: |
          echo "Cleaning up any partial spot resources..."
          terraform destroy -auto-approve || true

      - name: Fallback to On-Demand
        id: ondemand
        if: steps.spot.outputs.spot_success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
        run: |
          echo "Launching on-demand instances as fallback..."
          terraform apply -auto-approve
          echo "ondemand_success=true" >> $GITHUB_OUTPUT

      - name: Set Launch Results
        id: result
        run: |
          if [[ "${{ steps.spot.outputs.spot_success }}" == "true" ]]; then
            echo "arm64_launched=true" >> $GITHUB_OUTPUT
            echo "x86_launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=spot" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.ondemand.outputs.ondemand_success }}" == "true" ]]; then
            echo "arm64_launched=true" >> $GITHUB_OUTPUT
            echo "x86_launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=on-demand" >> $GITHUB_OUTPUT
          else
            echo "arm64_launched=false" >> $GITHUB_OUTPUT
            echo "x86_launched=false" >> $GITHUB_OUTPUT
            echo "instance_mode=none" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Wait for Runners
        run: |
          echo "Waiting for fast runners to register (60s)..."
          sleep 60

  benchmark-arm64:
    name: Fast Benchmark (ARM64)
    needs: launch
    if: needs.launch.outputs.arm64_launched == 'true'
    runs-on: [self-hosted, fast-arm64]
    timeout-minutes: 30
    continue-on-error: true

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25'

      - name: Build Server and Benchmark Tool
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

      - name: Run Benchmarks
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" -connections 128 -workers 4

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-arm64
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  benchmark-x86:
    name: Fast Benchmark (x86)
    needs: launch
    if: needs.launch.outputs.x86_launched == 'true'
    runs-on: [self-hosted, fast-x86]
    timeout-minutes: 30
    continue-on-error: true

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25'

      - name: Build Server and Benchmark Tool
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

      - name: Run Benchmarks
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" -connections 128 -workers 4

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-x86
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  report:
    name: Generate Report
    needs: [launch, benchmark-arm64, benchmark-x86]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      pull-requests: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download ARM64 Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-arm64
          path: downloaded/arm64
        continue-on-error: true

      - name: Download x86 Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-x86
          path: downloaded/x86
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Generate Charts
        run: |
          pip install matplotlib numpy

          mkdir -p results/charts/arm64 results/charts/x86

          # Find and process ARM64 results
          ARM64_JSON=$(find downloaded/arm64 -name "benchmark-*.json" 2>/dev/null | head -1)
          if [ -n "$ARM64_JSON" ]; then
            ARM64_DIR=$(dirname "$ARM64_JSON")
            echo "Found ARM64 results in: $ARM64_DIR"
            python scripts/generate_charts.py "$ARM64_DIR" results/charts/arm64
          else
            echo "No ARM64 JSON results found"
          fi

          # Find and process x86 results
          X86_JSON=$(find downloaded/x86 -name "benchmark-*.json" 2>/dev/null | head -1)
          if [ -n "$X86_JSON" ]; then
            X86_DIR=$(dirname "$X86_JSON")
            echo "Found x86 results in: $X86_DIR"
            python scripts/generate_charts.py "$X86_DIR" results/charts/x86
          else
            echo "No x86 JSON results found"
          fi

      - name: Upload Charts Artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-charts
          path: results/charts/
          retention-days: 30

      - name: Generate PR Comment
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          COMMENT_BODY="## Fast Benchmark Results (Preview)

          > **Note**: These are quick validation results using virtualized instances.
          > For official results, run the Metal benchmark after merge.
          > **Instance mode**: ${{ needs.launch.outputs.instance_mode }}

          ---
          "

          # Add ARM64 results
          if [ -f "results/charts/arm64/summary_arm64.md" ]; then
            COMMENT_BODY+="
          ### ARM64 (Graviton)

          $(cat results/charts/arm64/summary_arm64.md | tail -n +2)

          ---
          "
          else
            COMMENT_BODY+="
          ### ARM64 (Graviton)

          No ARM64 results available (benchmark may have failed)

          ---
          "
          fi

          # Add x86 results
          if [ -f "results/charts/x86/summary_x86.md" ]; then
            COMMENT_BODY+="
          ### x86 (Intel)

          $(cat results/charts/x86/summary_x86.md | tail -n +2)

          ---
          "
          else
            COMMENT_BODY+="
          ### x86 (Intel)

          No x86 results available (benchmark may have failed)

          ---
          "
          fi

          COMMENT_BODY+="
          ### Charts

          Download the full benchmark charts from the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).

          ---

          <sub>Generated by [Celeris Benchmark Suite](https://github.com/${{ github.repository }}) | Run ID: ${{ github.run_id }}</sub>
          "

          # Post or update comment
          PR_NUMBER=${{ github.event.pull_request.number }}

          EXISTING_COMMENT=$(gh api repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
            --jq '.[] | select(.body | contains("Fast Benchmark Results")) | .id' | head -1)

          if [ -n "$EXISTING_COMMENT" ]; then
            gh api repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT} \
              -X PATCH \
              -f body="$COMMENT_BODY"
            echo "Updated existing comment: $EXISTING_COMMENT"
          else
            gh api repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
              -f body="$COMMENT_BODY"
            echo "Created new comment on PR #${PR_NUMBER}"
          fi

      - name: Create Summary
        run: |
          echo "# Fast Benchmark Results (Preview)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> **Note**: These are quick validation results using virtualized instances." >> $GITHUB_STEP_SUMMARY
          echo "> For official results, run the Metal benchmark after merge." >> $GITHUB_STEP_SUMMARY
          echo "> **Instance mode**: ${{ needs.launch.outputs.instance_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## ARM64 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/charts/arm64/summary_arm64.md" ]; then
            cat results/charts/arm64/summary_arm64.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No ARM64 results available" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## x86 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/charts/x86/summary_x86.md" ]; then
            cat results/charts/x86/summary_x86.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No x86 results available" >> $GITHUB_STEP_SUMMARY
          fi

  cleanup:
    name: Cleanup Infrastructure
    needs: [launch, benchmark-arm64, benchmark-x86]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"

      - name: Terraform Destroy
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: ${{ needs.launch.outputs.instance_mode == 'on-demand' && 'true' || 'false' }}
        run: |
          terraform init
          terraform destroy -auto-approve || true
