name: Benchmark (Fast)

# Fast mode: Runs on PRs for quick trend validation
# Uses cheaper virtualized instances (c5.large, c6g.medium)
# Each architecture launches independently with spot -> on-demand fallback
# If spot instance is terminated mid-benchmark, automatically retries on on-demand
# with checkpoint support to continue from where it left off
#
# Requires approval: PR must have 'run-benchmarks' label added by maintainer

on:
  pull_request:
    branches: [main]
    types: [labeled, synchronize]
  workflow_dispatch:
    inputs:
      duration:
        description: 'Benchmark duration (e.g., 15s, 30s)'
        required: false
        default: '15s'
      benchmark_mode:
        description: 'Benchmark servers to test'
        required: false
        default: 'all'
        type: choice
        options:
          - baseline
          - theoretical
          - all

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

env:
  TF_VAR_repository_url: ${{ github.server_url }}/${{ github.repository }}
  TF_VAR_benchmark_mode: fast

jobs:
  authorize:
    name: Authorize Benchmark
    runs-on: ubuntu-latest
    outputs:
      authorized: ${{ steps.check.outputs.authorized }}
    steps:
      - name: Check Authorization
        id: check
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            PERMISSION=$(gh api repos/${{ github.repository }}/collaborators/${{ github.actor }}/permission --jq '.permission')
            if [[ "$PERMISSION" == "admin" || "$PERMISSION" == "maintain" || "$PERMISSION" == "write" ]]; then
              echo "authorized=true" >> $GITHUB_OUTPUT
              echo "User ${{ github.actor }} authorized (permission: $PERMISSION)"
            else
              echo "authorized=false" >> $GITHUB_OUTPUT
              echo "::error::User ${{ github.actor }} not authorized (permission: $PERMISSION)"
            fi
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ contains(github.event.pull_request.labels.*.name, 'run-benchmarks') }}" == "true" ]]; then
              echo "authorized=true" >> $GITHUB_OUTPUT
              echo "PR has 'run-benchmarks' label - authorized"
            else
              echo "authorized=false" >> $GITHUB_OUTPUT
              echo "::notice::PR needs 'run-benchmarks' label to run benchmarks. A maintainer must add this label."
            fi
          else
            echo "authorized=false" >> $GITHUB_OUTPUT
          fi

  # Launch ARM64 infrastructure independently
  launch-arm64:
    name: Launch ARM64 Infrastructure
    runs-on: ubuntu-latest
    needs: authorize
    if: needs.authorize.outputs.authorized == 'true'
    outputs:
      launched: ${{ steps.result.outputs.launched }}
      instance_mode: ${{ steps.result.outputs.instance_mode }}

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Try ARM64 Spot
        id: spot
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_arm64_only: "true"
        run: |
          echo "Attempting ARM64 spot (c6g.medium)..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "ARM64 spot launched successfully"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "ARM64 spot failed with exit code $EXIT_CODE"
          fi

      - name: Cleanup ARM64 Spot
        if: steps.spot.outputs.success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_arm64_only: "true"
        run: terraform destroy -auto-approve || true

      - name: Try ARM64 On-Demand
        id: ondemand
        if: steps.spot.outputs.success != 'true'
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
          TF_VAR_launch_arm64_only: "true"
        run: |
          echo "Attempting ARM64 on-demand (c6g.medium)..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "ARM64 on-demand launched successfully"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "ARM64 on-demand failed with exit code $EXIT_CODE"
          fi

      - name: Set ARM64 Launch Results
        id: result
        run: |
          if [[ "${{ steps.spot.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=spot" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.ondemand.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=on-demand" >> $GITHUB_OUTPUT
          else
            echo "launched=false" >> $GITHUB_OUTPUT
            echo "instance_mode=none" >> $GITHUB_OUTPUT
            echo "::error::All ARM64 launch attempts failed"
          fi

      - name: Wait for ARM64 Runner
        if: steps.result.outputs.launched == 'true'
        run: |
          echo "Waiting for ARM64 runner to register (60s)..."
          sleep 60

  # Launch x86 infrastructure independently
  launch-x86:
    name: Launch x86 Infrastructure
    runs-on: ubuntu-latest
    needs: authorize
    if: needs.authorize.outputs.authorized == 'true'
    outputs:
      launched: ${{ steps.result.outputs.launched }}
      instance_mode: ${{ steps.result.outputs.instance_mode }}

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Try x86 Spot
        id: spot
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_x86_only: "true"
        run: |
          echo "Attempting x86 spot (c5.large)..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "x86 spot launched successfully"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "x86 spot failed with exit code $EXIT_CODE"
          fi

      - name: Cleanup x86 Spot
        if: steps.spot.outputs.success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_x86_only: "true"
        run: terraform destroy -auto-approve || true

      - name: Try x86 On-Demand
        id: ondemand
        if: steps.spot.outputs.success != 'true'
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
          TF_VAR_launch_x86_only: "true"
        run: |
          echo "Attempting x86 on-demand (c5.large)..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "x86 on-demand launched successfully"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "x86 on-demand failed with exit code $EXIT_CODE"
          fi

      - name: Set x86 Launch Results
        id: result
        run: |
          if [[ "${{ steps.spot.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=spot" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.ondemand.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=on-demand" >> $GITHUB_OUTPUT
          else
            echo "launched=false" >> $GITHUB_OUTPUT
            echo "instance_mode=none" >> $GITHUB_OUTPUT
            echo "::error::All x86 launch attempts failed"
          fi

      - name: Wait for x86 Runner
        if: steps.result.outputs.launched == 'true'
        run: |
          echo "Waiting for x86 runner to register (60s)..."
          sleep 60

  benchmark-arm64:
    name: Fast Benchmark (ARM64)
    needs: launch-arm64
    if: needs.launch-arm64.outputs.launched == 'true'
    runs-on: [self-hosted, server-fast-arm64]
    timeout-minutes: 90
    continue-on-error: true  # Don't fail workflow - retry will handle spot termination

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25.5'

      - name: Build and Run
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench
          # Run with checkpoint support - saves progress after each benchmark
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" 

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-arm64
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  benchmark-x86:
    name: Fast Benchmark (x86)
    needs: launch-x86
    if: needs.launch-x86.outputs.launched == 'true'
    runs-on: [self-hosted, server-fast-x86]
    timeout-minutes: 90
    continue-on-error: true  # Don't fail workflow - retry will handle spot termination

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25.5'

      - name: Build and Run
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench
          # Run with checkpoint support - saves progress after each benchmark
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" 

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-x86
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  # Retry ARM64 on on-demand if spot was terminated
  retry-arm64:
    name: Retry ARM64 (On-Demand)
    needs: [authorize, launch-arm64, benchmark-arm64]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.authorize.outputs.authorized == 'true' &&
      needs.launch-arm64.outputs.launched == 'true' &&
      needs.launch-arm64.outputs.instance_mode == 'spot' &&
      needs.benchmark-arm64.outcome == 'failure'
    outputs:
      launched: ${{ steps.result.outputs.launched }}

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Cleanup Failed Spot Instance
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_arm64_only: "true"
        run: |
          echo "Cleaning up failed ARM64 spot instance..."
          terraform destroy -auto-approve || true

      - name: Launch ARM64 On-Demand
        id: launch
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
          TF_VAR_launch_arm64_only: "true"
        run: |
          echo "Launching ARM64 on-demand for retry..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "ARM64 on-demand launched successfully for retry"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "ARM64 on-demand failed with exit code $EXIT_CODE"
          fi

      - name: Set Retry Results
        id: result
        run: |
          if [[ "${{ steps.launch.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
          else
            echo "launched=false" >> $GITHUB_OUTPUT
            echo "::error::ARM64 on-demand retry launch failed"
          fi

      - name: Wait for ARM64 Runner
        if: steps.result.outputs.launched == 'true'
        run: |
          echo "Waiting for ARM64 on-demand runner to register (60s)..."
          sleep 60

  # Retry x86 on on-demand if spot was terminated
  retry-x86:
    name: Retry x86 (On-Demand)
    needs: [authorize, launch-x86, benchmark-x86]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.authorize.outputs.authorized == 'true' &&
      needs.launch-x86.outputs.launched == 'true' &&
      needs.launch-x86.outputs.instance_mode == 'spot' &&
      needs.benchmark-x86.outcome == 'failure'
    outputs:
      launched: ${{ steps.result.outputs.launched }}

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Cleanup Failed Spot Instance
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_x86_only: "true"
        run: |
          echo "Cleaning up failed x86 spot instance..."
          terraform destroy -auto-approve || true

      - name: Launch x86 On-Demand
        id: launch
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
          TF_VAR_launch_x86_only: "true"
        run: |
          echo "Launching x86 on-demand for retry..."
          set +e
          terraform apply -auto-approve
          EXIT_CODE=$?
          set -e
          if [ $EXIT_CODE -eq 0 ]; then
            echo "success=true" >> $GITHUB_OUTPUT
            echo "x86 on-demand launched successfully for retry"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            echo "x86 on-demand failed with exit code $EXIT_CODE"
          fi

      - name: Set Retry Results
        id: result
        run: |
          if [[ "${{ steps.launch.outputs.success }}" == "true" ]]; then
            echo "launched=true" >> $GITHUB_OUTPUT
          else
            echo "launched=false" >> $GITHUB_OUTPUT
            echo "::error::x86 on-demand retry launch failed"
          fi

      - name: Wait for x86 Runner
        if: steps.result.outputs.launched == 'true'
        run: |
          echo "Waiting for x86 on-demand runner to register (60s)..."
          sleep 60

  # Retry benchmark on ARM64 on-demand - continues from checkpoint
  retry-benchmark-arm64:
    name: Retry Benchmark (ARM64)
    needs: [retry-arm64, benchmark-arm64]
    if: |
      always() &&
      needs.retry-arm64.outputs.launched == 'true'
    runs-on: [self-hosted, server-fast-arm64]
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Download Previous Checkpoint
        uses: actions/download-artifact@v4
        with:
          name: fast-results-arm64
          path: results/
        continue-on-error: true

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25.5'

      - name: Build and Resume
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          echo "RETRY: Resuming benchmark on ARM64 on-demand instance"
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

          # Check if checkpoint exists and resume from it
          if [ -f results/checkpoint-arm64.json ]; then
            echo "Found checkpoint, resuming from previous progress..."
            ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION"  -resume
          else
            echo "No checkpoint found, starting fresh..."
            ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" 
          fi

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-arm64-retry
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  # Retry benchmark on x86 on-demand - continues from checkpoint
  retry-benchmark-x86:
    name: Retry Benchmark (x86)
    needs: [retry-x86, benchmark-x86]
    if: |
      always() &&
      needs.retry-x86.outputs.launched == 'true'
    runs-on: [self-hosted, server-fast-x86]
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Download Previous Checkpoint
        uses: actions/download-artifact@v4
        with:
          name: fast-results-x86
          path: results/
        continue-on-error: true

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25.5'

      - name: Build and Resume
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '15s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          echo "RETRY: Resuming benchmark on x86 on-demand instance"
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

          # Check if checkpoint exists and resume from it
          if [ -f results/checkpoint-x86.json ]; then
            echo "Found checkpoint, resuming from previous progress..."
            ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION"  -resume
          else
            echo "No checkpoint found, starting fresh..."
            ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" 
          fi

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fast-results-x86-retry
          path: results/
          retention-days: 7
          if-no-files-found: ignore

  report:
    name: Generate Report
    needs: [authorize, launch-arm64, launch-x86, benchmark-arm64, benchmark-x86, retry-arm64, retry-x86, retry-benchmark-arm64, retry-benchmark-x86]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.authorize.outputs.authorized == 'true' &&
      (needs.benchmark-arm64.outcome == 'success' || needs.benchmark-x86.outcome == 'success' ||
       needs.retry-benchmark-arm64.result == 'success' || needs.retry-benchmark-x86.result == 'success')
    permissions:
      pull-requests: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Download ARM64 Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-arm64
          path: downloaded/arm64
        continue-on-error: true

      - name: Download ARM64 Retry Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-arm64-retry
          path: downloaded/arm64-retry
        continue-on-error: true

      - name: Download x86 Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-x86
          path: downloaded/x86
        continue-on-error: true

      - name: Download x86 Retry Results
        uses: actions/download-artifact@v4
        with:
          name: fast-results-x86-retry
          path: downloaded/x86-retry
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Generate Charts
        env:
          ARM64_ORIGINAL_SUCCESS: ${{ needs.benchmark-arm64.outcome == 'success' }}
          ARM64_RETRY_SUCCESS: ${{ needs.retry-benchmark-arm64.result == 'success' }}
          X86_ORIGINAL_SUCCESS: ${{ needs.benchmark-x86.outcome == 'success' }}
          X86_RETRY_SUCCESS: ${{ needs.retry-benchmark-x86.result == 'success' }}
        run: |
          pip install matplotlib numpy

          mkdir -p results/charts/arm64 results/charts/x86

          # For ARM64: prefer retry results (which include merged checkpoint data)
          # Otherwise use original results
          if [[ "$ARM64_RETRY_SUCCESS" == "true" ]]; then
            ARM64_SOURCE="downloaded/arm64-retry"
            echo "Using ARM64 retry results (includes checkpoint data)"
          elif [ -d "downloaded/arm64" ]; then
            ARM64_SOURCE="downloaded/arm64"
            echo "Using ARM64 original results"
          else
            ARM64_SOURCE=""
            echo "No ARM64 results available"
          fi

          # For x86: prefer retry results (which include merged checkpoint data)
          if [[ "$X86_RETRY_SUCCESS" == "true" ]]; then
            X86_SOURCE="downloaded/x86-retry"
            echo "Using x86 retry results (includes checkpoint data)"
          elif [ -d "downloaded/x86" ]; then
            X86_SOURCE="downloaded/x86"
            echo "Using x86 original results"
          else
            X86_SOURCE=""
            echo "No x86 results available"
          fi

          # Find and process ARM64 results
          if [ -n "$ARM64_SOURCE" ]; then
            ARM64_JSON=$(find "$ARM64_SOURCE" -name "benchmark-*.json" 2>/dev/null | head -1)
            if [ -n "$ARM64_JSON" ]; then
              ARM64_DIR=$(dirname "$ARM64_JSON")
              echo "Found ARM64 results in: $ARM64_DIR"
              python scripts/generate_charts.py "$ARM64_DIR" results/charts/arm64
            else
              echo "No ARM64 JSON results found"
            fi
          fi

          # Find and process x86 results
          if [ -n "$X86_SOURCE" ]; then
            X86_JSON=$(find "$X86_SOURCE" -name "benchmark-*.json" 2>/dev/null | head -1)
            if [ -n "$X86_JSON" ]; then
              X86_DIR=$(dirname "$X86_JSON")
              echo "Found x86 results in: $X86_DIR"
              python scripts/generate_charts.py "$X86_DIR" results/charts/x86
            else
              echo "No x86 JSON results found"
            fi
          fi

      - name: Upload Charts Artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-charts
          path: results/charts/
          retention-days: 30

      - name: Generate PR Comment
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ github.token }}
          ARM64_MODE: ${{ needs.launch-arm64.outputs.instance_mode }}
          X86_MODE: ${{ needs.launch-x86.outputs.instance_mode }}
          ARM64_RETRIED: ${{ needs.retry-benchmark-arm64.result == 'success' }}
          X86_RETRIED: ${{ needs.retry-benchmark-x86.result == 'success' }}
        run: |
          # Determine final instance mode for each arch
          if [[ "$ARM64_RETRIED" == "true" ]]; then
            ARM64_FINAL_MODE="on-demand (retry)"
          else
            ARM64_FINAL_MODE="$ARM64_MODE"
          fi

          if [[ "$X86_RETRIED" == "true" ]]; then
            X86_FINAL_MODE="on-demand (retry)"
          else
            X86_FINAL_MODE="$X86_MODE"
          fi

          COMMENT_BODY="## Fast Benchmark Results (Preview)

          > **Note**: These are quick validation results using virtualized instances.
          > For official results, run the Metal benchmark after merge.

          | Architecture | Instance Mode |
          |--------------|---------------|
          | ARM64 | $ARM64_FINAL_MODE |
          | x86 | $X86_FINAL_MODE |

          ---
          "

          # Add ARM64 results
          if [ -f "results/charts/arm64/summary_arm64.md" ]; then
            COMMENT_BODY+="
          ### ARM64 (Graviton)

          $(cat results/charts/arm64/summary_arm64.md | tail -n +2)

          ---
          "
          else
            COMMENT_BODY+="
          ### ARM64 (Graviton)

          No ARM64 results available (benchmark may have failed or instance unavailable)

          ---
          "
          fi

          # Add x86 results
          if [ -f "results/charts/x86/summary_x86.md" ]; then
            COMMENT_BODY+="
          ### x86 (Intel)

          $(cat results/charts/x86/summary_x86.md | tail -n +2)

          ---
          "
          else
            COMMENT_BODY+="
          ### x86 (Intel)

          No x86 results available (benchmark may have failed or instance unavailable)

          ---
          "
          fi

          COMMENT_BODY+="
          ### Charts

          Download the full benchmark charts from the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).

          ---

          <sub>Generated by [Celeris Benchmark Suite](https://github.com/${{ github.repository }}) | Run ID: ${{ github.run_id }}</sub>
          "

          # Post or update comment
          PR_NUMBER=${{ github.event.pull_request.number }}

          EXISTING_COMMENT=$(gh api repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
            --jq '.[] | select(.body | contains("Fast Benchmark Results")) | .id' | head -1)

          if [ -n "$EXISTING_COMMENT" ]; then
            gh api repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT} \
              -X PATCH \
              -f body="$COMMENT_BODY"
            echo "Updated existing comment: $EXISTING_COMMENT"
          else
            gh api repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
              -f body="$COMMENT_BODY"
            echo "Created new comment on PR #${PR_NUMBER}"
          fi

      - name: Create Summary
        env:
          ARM64_MODE: ${{ needs.launch-arm64.outputs.instance_mode }}
          X86_MODE: ${{ needs.launch-x86.outputs.instance_mode }}
          ARM64_RETRIED: ${{ needs.retry-benchmark-arm64.result == 'success' }}
          X86_RETRIED: ${{ needs.retry-benchmark-x86.result == 'success' }}
        run: |
          # Determine final instance mode for each arch
          if [[ "$ARM64_RETRIED" == "true" ]]; then
            ARM64_FINAL_MODE="on-demand (retry)"
          else
            ARM64_FINAL_MODE="$ARM64_MODE"
          fi

          if [[ "$X86_RETRIED" == "true" ]]; then
            X86_FINAL_MODE="on-demand (retry)"
          else
            X86_FINAL_MODE="$X86_MODE"
          fi

          echo "# Fast Benchmark Results (Preview)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> **Note**: These are quick validation results using virtualized instances." >> $GITHUB_STEP_SUMMARY
          echo "> For official results, run the Metal benchmark after merge." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Architecture | Instance Mode |" >> $GITHUB_STEP_SUMMARY
          echo "|--------------|---------------|" >> $GITHUB_STEP_SUMMARY
          echo "| ARM64 | $ARM64_FINAL_MODE |" >> $GITHUB_STEP_SUMMARY
          echo "| x86 | $X86_FINAL_MODE |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## ARM64 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/charts/arm64/summary_arm64.md" ]; then
            cat results/charts/arm64/summary_arm64.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No ARM64 results available" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## x86 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/charts/x86/summary_x86.md" ]; then
            cat results/charts/x86/summary_x86.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No x86 results available" >> $GITHUB_STEP_SUMMARY
          fi

  cleanup-arm64:
    name: Cleanup ARM64 Infrastructure
    needs: [authorize, launch-arm64, benchmark-arm64, retry-arm64, retry-benchmark-arm64]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.authorize.outputs.authorized == 'true' &&
      (needs.launch-arm64.outputs.launched == 'true' || needs.retry-arm64.outputs.launched == 'true')

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Determine Instance Mode
        id: mode
        env:
          ORIGINAL_MODE: ${{ needs.launch-arm64.outputs.instance_mode }}
          RETRY_LAUNCHED: ${{ needs.retry-arm64.outputs.launched }}
        run: |
          # If retry launched, we're on on-demand; otherwise use original mode
          if [[ "$RETRY_LAUNCHED" == "true" ]]; then
            echo "use_on_demand=true" >> $GITHUB_OUTPUT
          elif [[ "$ORIGINAL_MODE" == "on-demand" ]]; then
            echo "use_on_demand=true" >> $GITHUB_OUTPUT
          else
            echo "use_on_demand=false" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Destroy ARM64
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_arm64_only: "true"
          TF_VAR_use_on_demand: ${{ steps.mode.outputs.use_on_demand }}
        run: |
          terraform init
          terraform destroy -auto-approve || true

  cleanup-x86:
    name: Cleanup x86 Infrastructure
    needs: [authorize, launch-x86, benchmark-x86, retry-x86, retry-benchmark-x86]
    runs-on: ubuntu-latest
    if: |
      always() &&
      needs.authorize.outputs.authorized == 'true' &&
      (needs.launch-x86.outputs.launched == 'true' || needs.retry-x86.outputs.launched == 'true')

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - name: Determine Instance Mode
        id: mode
        env:
          ORIGINAL_MODE: ${{ needs.launch-x86.outputs.instance_mode }}
          RETRY_LAUNCHED: ${{ needs.retry-x86.outputs.launched }}
        run: |
          # If retry launched, we're on on-demand; otherwise use original mode
          if [[ "$RETRY_LAUNCHED" == "true" ]]; then
            echo "use_on_demand=true" >> $GITHUB_OUTPUT
          elif [[ "$ORIGINAL_MODE" == "on-demand" ]]; then
            echo "use_on_demand=true" >> $GITHUB_OUTPUT
          else
            echo "use_on_demand=false" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Destroy x86
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_launch_x86_only: "true"
          TF_VAR_use_on_demand: ${{ steps.mode.outputs.use_on_demand }}
        run: |
          terraform init
          terraform destroy -auto-approve || true

  final-status:
    name: Final Status
    needs: [benchmark-arm64, benchmark-x86, retry-benchmark-arm64, retry-benchmark-x86]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Determine final status
        run: |
          ARM64_OK="false"
          X86_OK="false"

          # Use 'outcome' for benchmark jobs (they have continue-on-error)
          # Use 'result' for retry jobs (they don't have continue-on-error)
          if [[ "${{ needs.benchmark-arm64.outcome }}" == "success" ]] || \
             [[ "${{ needs.retry-benchmark-arm64.result }}" == "success" ]]; then
            ARM64_OK="true"
          fi

          if [[ "${{ needs.benchmark-x86.outcome }}" == "success" ]] || \
             [[ "${{ needs.retry-benchmark-x86.result }}" == "success" ]]; then
            X86_OK="true"
          fi

          echo "ARM64: $ARM64_OK"
          echo "x86: $X86_OK"

          # At least one architecture must succeed
          if [[ "$ARM64_OK" == "true" ]] || [[ "$X86_OK" == "true" ]]; then
            echo "Benchmark completed successfully"
            exit 0
          else
            echo "All benchmarks failed"
            exit 1
          fi
