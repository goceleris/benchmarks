name: Benchmark (Metal)

# Metal mode: Official benchmarks on bare-metal instances
# Triggered on push to main, new releases, or manually by maintainers
# Uses c5.metal (x86) and c6g.metal (ARM64)

on:
  push:
    branches: [main]
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      duration:
        description: 'Benchmark duration (e.g., 30s, 60s)'
        required: false
        default: '30s'
      benchmark_mode:
        description: 'Benchmark servers to test'
        required: false
        default: 'all'
        type: choice
        options:
          - baseline
          - theoretical
          - all

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

env:
  TF_VAR_repository_url: ${{ github.server_url }}/${{ github.repository }}
  TF_VAR_benchmark_mode: metal

jobs:
  authorize:
    name: Authorize Caller
    runs-on: ubuntu-latest
    if: github.event_name == 'release' || github.event_name == 'workflow_dispatch' || github.event_name == 'push'
    steps:
      - name: Check Permissions
        if: github.event_name == 'workflow_dispatch'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          PERMISSION=$(gh api repos/${{ github.repository }}/collaborators/${{ github.actor }}/permission --jq '.permission')

          echo "User: ${{ github.actor }}"
          echo "Permission level: $PERMISSION"

          if [[ "$PERMISSION" != "admin" && "$PERMISSION" != "maintain" && "$PERMISSION" != "write" ]]; then
            echo "::error::Unauthorized: Only maintainers and owners can trigger metal benchmarks"
            exit 1
          fi

          echo "User ${{ github.actor }} authorized with permission: $PERMISSION"

  launch:
    name: Launch Metal Infrastructure
    runs-on: ubuntu-latest
    needs: authorize
    outputs:
      arm64_launched: ${{ steps.result.outputs.arm64_launched }}
      x86_launched: ${{ steps.result.outputs.x86_launched }}
      instance_mode: ${{ steps.result.outputs.instance_mode }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Try Spot Instances
        id: spot
        continue-on-error: true
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
        run: |
          echo "Attempting to launch spot instances..."
          if terraform apply -auto-approve; then
            echo "spot_success=true" >> $GITHUB_OUTPUT
            echo "Spot instances launched successfully"
          else
            echo "spot_success=false" >> $GITHUB_OUTPUT
            echo "Spot instances failed, will try on-demand"
          fi

      - name: Cleanup Failed Spot
        if: steps.spot.outputs.spot_success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
        run: |
          echo "Cleaning up any partial spot resources..."
          terraform destroy -auto-approve || true

      - name: Fallback to On-Demand
        id: ondemand
        if: steps.spot.outputs.spot_success != 'true'
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: "true"
        run: |
          echo "Launching on-demand instances as fallback..."
          terraform apply -auto-approve
          echo "ondemand_success=true" >> $GITHUB_OUTPUT

      - name: Set Launch Results
        id: result
        run: |
          if [[ "${{ steps.spot.outputs.spot_success }}" == "true" ]]; then
            echo "arm64_launched=true" >> $GITHUB_OUTPUT
            echo "x86_launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=spot" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.ondemand.outputs.ondemand_success }}" == "true" ]]; then
            echo "arm64_launched=true" >> $GITHUB_OUTPUT
            echo "x86_launched=true" >> $GITHUB_OUTPUT
            echo "instance_mode=on-demand" >> $GITHUB_OUTPUT
          else
            echo "arm64_launched=false" >> $GITHUB_OUTPUT
            echo "x86_launched=false" >> $GITHUB_OUTPUT
            echo "instance_mode=none" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Wait for Metal Runners
        run: |
          echo "Waiting for metal runners to boot and register (120s)..."
          sleep 120

  benchmark-arm64:
    name: Metal Benchmark (ARM64 Graviton)
    needs: launch
    if: needs.launch.outputs.arm64_launched == 'true'
    runs-on: [self-hosted, metal-arm64]
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25'

      - name: Build Server and Benchmark Tool
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

      - name: Run Official Benchmarks
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '30s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          echo "Running OFFICIAL metal benchmarks"
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" -connections 256 -workers 8

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: metal-results-arm64
          path: results/
          retention-days: 90

  benchmark-x86:
    name: Metal Benchmark (x86 Intel)
    needs: launch
    if: needs.launch.outputs.x86_launched == 'true'
    runs-on: [self-hosted, metal-x86]
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.25'

      - name: Build Server and Benchmark Tool
        run: |
          go mod download
          go build -o bin/server ./cmd/server
          go build -o bin/bench ./cmd/bench

      - name: Run Official Benchmarks
        env:
          BENCHMARK_DURATION: ${{ github.event.inputs.duration || '30s' }}
          BENCHMARK_MODE: ${{ github.event.inputs.benchmark_mode || 'all' }}
        run: |
          echo "Running OFFICIAL metal benchmarks"
          ./bin/bench -mode "$BENCHMARK_MODE" -duration "$BENCHMARK_DURATION" -connections 256 -workers 8

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: metal-results-x86
          path: results/
          retention-days: 90

  report:
    name: Generate Official Report
    needs: [launch, benchmark-arm64, benchmark-x86]
    runs-on: ubuntu-latest
    if: always() && (needs.benchmark-arm64.result == 'success' || needs.benchmark-x86.result == 'success')
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download ARM64 Results
        uses: actions/download-artifact@v4
        with:
          name: metal-results-arm64
          path: downloaded/arm64
        continue-on-error: true

      - name: Download x86 Results
        uses: actions/download-artifact@v4
        with:
          name: metal-results-x86
          path: downloaded/x86
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Generate Charts
        run: |
          pip install matplotlib numpy

          mkdir -p results/latest/arm64 results/latest/x86

          # Process ARM64 results
          if [ -d "downloaded/arm64" ]; then
            ARM64_JSON=$(find downloaded/arm64 -name "benchmark-*.json" 2>/dev/null | head -1)
            if [ -n "$ARM64_JSON" ]; then
              ARM64_DIR=$(dirname "$ARM64_JSON")
              echo "Found ARM64 results in: $ARM64_DIR"
              python scripts/generate_charts.py "$ARM64_DIR" results/latest/arm64
              cp "$ARM64_DIR"/*.json results/latest/arm64/ 2>/dev/null || true
            fi
          fi

          # Process x86 results
          if [ -d "downloaded/x86" ]; then
            X86_JSON=$(find downloaded/x86 -name "benchmark-*.json" 2>/dev/null | head -1)
            if [ -n "$X86_JSON" ]; then
              X86_DIR=$(dirname "$X86_JSON")
              echo "Found x86 results in: $X86_DIR"
              python scripts/generate_charts.py "$X86_DIR" results/latest/x86
              cp "$X86_DIR"/*.json results/latest/x86/ 2>/dev/null || true
            fi
          fi

      - name: Upload Official Charts
        uses: actions/upload-artifact@v4
        with:
          name: official-benchmark-charts
          path: results/latest/
          retention-days: 365

      - name: Commit Results to Repository
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Add timestamp and metadata
          echo "Last updated: $(date -u)" > results/latest/TIMESTAMP
          echo "Triggered by: ${{ github.actor }}" >> results/latest/TIMESTAMP
          echo "Event: ${{ github.event_name }}" >> results/latest/TIMESTAMP
          echo "Instance mode: ${{ needs.launch.outputs.instance_mode }}" >> results/latest/TIMESTAMP

          # If this is a release, also create a version-specific folder
          if [ "${{ github.event_name }}" == "release" ]; then
            VERSION="${{ github.event.release.tag_name }}"
            mkdir -p "results/${VERSION}/arm64" "results/${VERSION}/x86"

            # Copy results to version folder
            if [ -d "results/latest/arm64" ]; then
              cp -r results/latest/arm64/* "results/${VERSION}/arm64/" 2>/dev/null || true
            fi

            if [ -d "results/latest/x86" ]; then
              cp -r results/latest/x86/* "results/${VERSION}/x86/" 2>/dev/null || true
            fi

            echo "Release: ${VERSION}" > "results/${VERSION}/RELEASE_INFO"
            echo "Date: $(date -u)" >> "results/${VERSION}/RELEASE_INFO"

            git add -f "results/${VERSION}/"
          fi

          git add -f results/latest/
          git commit -m "chore: update benchmark results [skip ci]" || echo "No changes to commit"
          git push || echo "Push failed (may need permissions)"

      - name: Create Summary
        run: |
          echo "# Official Metal Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Release**: ${{ github.event.release.tag_name || 'Manual Run' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Instance mode**: ${{ needs.launch.outputs.instance_mode }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ github.event_name }}" == "release" ]; then
            echo "> Results committed to \`results/latest/\` and \`results/${{ github.event.release.tag_name }}/\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "> Results committed to \`results/latest/\`" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## ARM64 (Graviton c6g.metal)" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/latest/arm64/summary_arm64.md" ]; then
            cat results/latest/arm64/summary_arm64.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No ARM64 results available" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## x86 (Intel c5.metal)" >> $GITHUB_STEP_SUMMARY
          if [ -f "results/latest/x86/summary_x86.md" ]; then
            cat results/latest/x86/summary_x86.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No x86 results available" >> $GITHUB_STEP_SUMMARY
          fi

  cleanup:
    name: Cleanup Infrastructure
    needs: [launch, benchmark-arm64, benchmark-x86]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"

      - name: Terraform Destroy
        working-directory: terraform
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_gh_pat_runner_token: ${{ secrets.GH_PAT_RUNNER_TOKEN }}
          TF_VAR_use_on_demand: ${{ needs.launch.outputs.instance_mode == 'on-demand' && 'true' || 'false' }}
        run: |
          terraform init
          terraform destroy -auto-approve || true
